---
title: "The Safety Gap Toolkit: Evaluating Hidden Dangers of Open-Source Models"
date: 2025-07-08
publishDate: 2025-07-08
authors: ["Ann-Kathrin Dombrowski", "Dillon Bowen", "Adam Gleave", "Chris Cundy"]
publication_types: ["3"]
abstract: "Open-weight large language models (LLMs) unlock huge benefits in innovation, personalization, privacy, and democratization. However, their core advantage - modifiability - opens the door to systemic risks: bad actors can trivially subvert current safeguards, turning beneficial models into tools for harm. This leads to a 'safety gap': the difference in dangerous capabilities between a model with intact safeguards and one that has been stripped of those safeguards. We open-source a toolkit to estimate the safety gap for state-of-the-art open-weight models. As a case study, we evaluate biochemical and cyber capabilities, refusal rates, and generation quality of models from two families (Llama-3 and Qwen-2.5) across a range of parameter scales (0.5B to 405B) using different safeguard removal techniques. Our experiments reveal that the safety gap widens as model scale increases and effective dangerous capabilities grow substantially when safeguards are removed. We hope that the Safety Gap Toolkit will serve as an evaluation framework for common open-source models and as a motivation for developing and testing tamper-resistant safeguards. We welcome contributions to the toolkit from the community."
featured: false
publication: "*Preprint*"
url_pdf: https://arxiv.org/pdf/2507.11544
---
